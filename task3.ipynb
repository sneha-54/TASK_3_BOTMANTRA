{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments are: ['France is the largest country in Western Europe and the third-largest in Europe as a whole.A accès aux chiens et aux frontaux qui lui ont été il peut consulter et modifier ses collectionset exporter Cet article concerne le pays européen aujourd’hui appelé République française.Pour d’autres usages du nom France, Pour une aide rapide et effective, veuiller trouver votre aidedans le menu ci-dessus.Motoring events began soon after the construction of the first successful gasoline-fueled automobiles.The quick brown fox jumped over the lazy dog', 'это компьютерный портал для гиков. It was a beautiful day ', 'Finnish: Quora on suosikkinettisivujani. Quorasta on tullut minulle tärkeä vapaa-ajanviettopaikka. Pidän Quoraan kirjoittamisesta hyvin paljon, ja tarkoitukseni on kirjoittaa mahdollisimman moneen Quoran kieliversioon. Eniten olen kirjoittanut englanninkieliseen versioon, mutta jonkin verran olen käyttänyt myös saksan- ja japaninkielisiä versioita, ja nyt on versio avattu myös suomeksi. Kirjoittaessani vastauksia kuuntelen joskus musiikkia kuulokkeilla, yleensä barokkia (kuten Bachin urkuteoksia), toisinaan jazzia. Kirjoitettuani hyvän vastauksen tunnen aina saavuttaneeni jotakin. Toivon Quoran säilyvän pitkään, sillä mistä sivusta olisi Quoraksi Quoran paikalle?', 'Gloss: Quora is favourtie-website-PL.PART.-my. Quora-ELAT. is become me-ALLAT. leisure-GEN.-spending-place. Like-1st.PERS.SG. Quora-ILLAT. writing-ELAT. very much, and purpose-my is write as-far-as-possible many-ILLAT. Quora-GEN. language-version-ILLAT. Most am written English-language-ILLAT. version-ILLAT., but some amount am used also German and English-language-PL.PART. version-PL.PART, and now is version opened-IMPERS. also Finnish-TRANSL. Write-INF.INESS.SG.1.PERS. answer-PL.PART. listen.SG.1st.PERS. sometimes music-PART. headphone-PL.ADESS., usuallu baroque-PART. (such-as Bach.GEN organ-music-PART.), sometimes jazz-PART. Write-PAST.PARTIC.PART.SG.1st.PERS. good.ACC. answer.ACC. feel-SG.1st.PERS. accomplish-PAST.PARTIC.ACT.SG.1st.PERS. something-PART. Hope-SG.1st.PERS. Quora-ACC. be-preserved-PARTIC.ACT.ACC. long-ILLAT., for what-ELAT. site-ELAT. be-COND.SG.3rd.PERS. Quora-TRANSL. Quora-GEN. place-ALLAT.'] \n",
      "No. of comments are: 4\n",
      "No. of characters with spaces 2195\n",
      "No. of words 244\n",
      "Finnish\n"
     ]
    }
   ],
   "source": [
    "#pip install textblob\n",
    "#pip install pycountry\n",
    "from docx import Document\n",
    "from lxml import etree\n",
    "import zipfile\n",
    "ooXMLns = {'w':'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "#Function to extract all the comments of document(Same as accepted answer)\n",
    "#Returns a dictionary with comment id as key and comment string as value\n",
    "def get_document_comments(docxFileName):\n",
    "    comments_dict={}\n",
    "    docxZip = zipfile.ZipFile(docxFileName)\n",
    "    commentsXML = docxZip.read('word/comments.xml')\n",
    "    et = etree.XML(commentsXML)\n",
    "    comments = et.xpath('//w:comment',namespaces=ooXMLns)\n",
    "    for c in comments:\n",
    "        comment=c.xpath('string(.)',namespaces=ooXMLns)\n",
    "        comment_id=c.xpath('@w:id',namespaces=ooXMLns)[0]\n",
    "        comments_dict[comment_id]=comment\n",
    "    return comments_dict\n",
    "#Function to fetch all the comments in a paragraph\n",
    "def paragraph_comments(paragraph,comments_dict):\n",
    "    comments=[]\n",
    "    for run in paragraph.runs:\n",
    "        comment_reference=run._r.xpath(\"./w:commentReference\")\n",
    "        if comment_reference:\n",
    "            comment_id=comment_reference[0].xpath('@w:id',namespaces=ooXMLns)[0]\n",
    "            comment=comments_dict[comment_id]\n",
    "            comments.append(comment)\n",
    "    return comments\n",
    "#Function to fetch all comments with their referenced paragraph\n",
    "#This will return list like this [{'Paragraph text': [comment 1,comment 2]}]\n",
    "def comments_with_reference_paragraph(docxFileName):\n",
    "    document = Document(docxFileName)\n",
    "    comments_dict=get_document_comments(docxFileName)\n",
    "    comments_with_their_reference_paragraph=[]\n",
    "    for paragraph in document.paragraphs:  \n",
    "        if comments_dict: \n",
    "            comments=paragraph_comments(paragraph,comments_dict)  \n",
    "            if comments:\n",
    "                comments_with_their_reference_paragraph.append({paragraph.text: comments})\n",
    "    return comments_with_their_reference_paragraph\n",
    "if __name__==\"__main__\":\n",
    "    document=\"highlights.docx\"  #filepath for the input document\n",
    "    com=comments_with_reference_paragraph(document)\n",
    "    l=[]\n",
    "    for i in com:\n",
    "        l.extend(list(i.values())[0])\n",
    "    print('Comments are:',l,'\\nNo. of comments are:',len(l))\n",
    "    char_count=0  #character count in comment with spaces\n",
    "    space_count=0  #it will calculate word count\n",
    "    for i in l:\n",
    "        space_count+=1\n",
    "        char_count+=len(i)\n",
    "        for j in i:\n",
    "            if j==\" \":\n",
    "                space_count+=1\n",
    "    print('No. of characters with spaces',char_count) \n",
    "    print('No. of words',space_count+1) \n",
    "    from textblob import TextBlob\n",
    "    text=\" \".join(l)\n",
    "    lang = TextBlob(text)\n",
    "    l=lang.detect_language()\n",
    "    from pycountry import languages\n",
    "    lang_name = languages.get(alpha_2=l).name\n",
    "    print(lang_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document=Document('ctask.docx')\n",
    "core_properties = document.core_properties\n",
    "core_properties.author = \"vishal\"\n",
    "document.save('author_change.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
